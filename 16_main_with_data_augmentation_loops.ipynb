{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "16 main_with_data_augmentation_loops.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "17YBXYsa_eN1RNre0N2RUA1SxvRrIOnQS",
      "authorship_tag": "ABX9TyP8Ypj/M1999BTNxcrstb/F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakobbaumgartner/CNN-HotDog-Classifier/blob/master/16_main_with_data_augmentation_loops.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzLPSpwt-50c"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\r\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\r\n",
        "from tensorflow.keras.callbacks import TensorBoard\r\n",
        "from keras import backend as K\r\n",
        "\r\n",
        "%reload_ext tensorboard\r\n",
        "\r\n",
        "\r\n",
        "import time\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "A268xpRi_VJ3",
        "outputId": "83e1e464-f965-4cf6-8e5c-a3dbf95d9f70"
      },
      "source": [
        "tf.keras.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pId__zSmALyc"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "import cv2\r\n",
        "from tqdm import tqdm\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRzU_DlhFg5h"
      },
      "source": [
        "Če imam izbrano GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GCyE-yoFnNhZ",
        "outputId": "ffad4250-8757-41bf-da94-979a7e986725"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOd0JkpXHHYX"
      },
      "source": [
        "# categories = [\"hot_dog\", \"not_hot_dog\"]\r\n",
        "train_datadir = \"drive/MyDrive/Colab Notebooks/seefood2/train\"\r\n",
        "validation_datadir = \"drive/MyDrive/Colab Notebooks/seefood2/validation\"\r\n",
        "# os.getcwd()\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSQChwpcwhx_"
      },
      "source": [
        "Zaradi majhnega nabora podatkov, s katerimi obratujem, bom s pomočjo ImageDataGenerator podatke razširil tako, da bom slike rotiral, zrcalil, raztegoval."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfF0Q-RbVe7d"
      },
      "source": [
        "\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PzZTu5CK-T1"
      },
      "source": [
        " *The basic CNN structure is as follows: Convolution -> Pooling -> Convolution -> Pooling -> Fully Connected Layer -> Output*\r\n",
        "\r\n",
        "*Convolution is the act of taking the original data, and creating feature maps from it.Pooling is down-sampling, most often in the form of \"max-pooling,\" where we select a region, and then take the maximum value in that region, and that becomes the new value for the entire region. Fully Connected Layers are typical neural networks, where all nodes are \"fully connected.\" The convolutional layers are not fully connected like a traditional neural network.* "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvKSm8nUL0WF"
      },
      "source": [
        "\r\n",
        "Na tej točki začnemo zares načrtovati nevronsko mrežo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d232PAP240H9",
        "outputId": "1aa7dd8b-5505-4876-fbfa-fbf52dadbb7e"
      },
      "source": [
        "\r\n",
        "\r\n",
        "batch_sizes = [16, 32]\r\n",
        "\r\n",
        "imsizees = [80, 100, 150]\r\n",
        "\r\n",
        "number_of_conv_layers = [1,2,3]\r\n",
        "# number_of_dense_layers = [1,2,3]\r\n",
        "size_of_conv_layers = [16,32,64, 128]\r\n",
        "size_of_dense_layers = [16,32,64]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "for batch_size in batch_sizes:\r\n",
        "    for imsizee in tqdm(imsizees):\r\n",
        "        for number_of_conv_layer in number_of_conv_layers:\r\n",
        "            for size_of_conv_layer in size_of_conv_layers:\r\n",
        "                for size_of_dense_layer in size_of_dense_layers:\r\n",
        "\r\n",
        "                    print(\"\\n------------------------------------------\")\r\n",
        "                    print(\"\\nbatch_size: \" + str(batch_size) + \"  imsizee: \" + str(imsizee) + \"  number_of_conv_layer: \" + str(number_of_conv_layer) + \"  size_of_conv_layer: \" + str(size_of_conv_layer) + \"  size_of_dense_layer: \" + str(size_of_dense_layer))\r\n",
        "\r\n",
        "                    train_datagen = ImageDataGenerator(\r\n",
        "                            rotation_range=40,  # rotiramo\r\n",
        "                            width_shift_range=0.2, # raztezamo\r\n",
        "                            height_shift_range=0.2,\r\n",
        "                            rescale=1./255, # normaliziramo\r\n",
        "                            shear_range=0.2,\r\n",
        "                            zoom_range=0.2,\r\n",
        "                            horizontal_flip=False,\r\n",
        "                            vertical_flip = True,\r\n",
        "                            fill_mode='nearest')\r\n",
        "\r\n",
        "                    test_datagen = ImageDataGenerator(rescale=1./255) # za testiranje fotografije le normaliziramo\r\n",
        "\r\n",
        "                    train_generator = train_datagen.flow_from_directory(\r\n",
        "                        train_datadir,\r\n",
        "                        target_size = (imsizee,imsizee),\r\n",
        "                        batch_size = batch_size,\r\n",
        "                        class_mode='binary'\r\n",
        "                        )\r\n",
        "\r\n",
        "                    validation_generator = test_datagen.flow_from_directory(\r\n",
        "                            validation_datadir,\r\n",
        "                            target_size=(imsizee, imsizee),\r\n",
        "                            batch_size=batch_size,\r\n",
        "                            class_mode='binary')\r\n",
        "\r\n",
        "\r\n",
        "                    if K.image_data_format() == 'channels_first':\r\n",
        "                        input_shape = (3, imsizee, imsizee)\r\n",
        "                    else:\r\n",
        "                        input_shape = (imsizee, imsizee, 3)\r\n",
        "\r\n",
        "                    model = Sequential()\r\n",
        "\r\n",
        "                    for _ in range(number_of_conv_layer):\r\n",
        "                        model.add(Conv2D(size_of_conv_layer, (3, 3), input_shape=input_shape))\r\n",
        "                        model.add(Activation('relu'))\r\n",
        "                        model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "\r\n",
        "                    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\r\n",
        "\r\n",
        "                    model.add(Dense(size_of_dense_layer))\r\n",
        "                    model.add(Activation('relu'))\r\n",
        "\r\n",
        "                    model.add(Dropout(0.5))\r\n",
        "\r\n",
        "                    model.add(Dense(1))\r\n",
        "                    model.add(Activation('sigmoid'))\r\n",
        "\r\n",
        "                    model.compile(loss='binary_crossentropy',\r\n",
        "                                  optimizer='rmsprop',\r\n",
        "                                  metrics=['accuracy'])\r\n",
        "\r\n",
        "                    tensorboard = TensorBoard(log_dir=\"logs2/first_try16_batch_size_{}_size_of_dense_layer_{}_number_of_conv_layers_{}_imsizee_{}_size_of_conv_layer_{}\".format(batch_size, size_of_dense_layer, number_of_conv_layers, imsizee, size_of_conv_layer),\r\n",
        "                                              histogram_freq=1)\r\n",
        "\r\n",
        "                 \r\n",
        "\r\n",
        "                    model.fit_generator(\r\n",
        "                            train_generator,\r\n",
        "                            steps_per_epoch=1652 // batch_size,\r\n",
        "                            epochs=65,\r\n",
        "                            validation_data=validation_generator,\r\n",
        "                            validation_steps=168 // batch_size,\r\n",
        "                            callbacks = [tensorboard])\r\n",
        "\r\n",
        "                    model.save_weights('first_try16' + 'batch_size_' + str(batch_size) + 'size_of_dense_layer_' +str(size_of_dense_layer) + 'number_of_conv_layers_' + str(number_of_conv_layers) + 'imsizee_' + str(imsizee) + '.h5')  # always save your weights after training or during training"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------------------------------------\n",
            "\n",
            "batch_size: 16  imsizee: 80  number_of_conv_layer: 1  size_of_conv_layer: 16  size_of_dense_layer: 16\n",
            "Found 1652 images belonging to 2 classes.\n",
            "Found 168 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/65\n",
            "  2/103 [..............................] - ETA: 4:42 - loss: 0.9758 - accuracy: 0.6875 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdJBmZa85Oc1"
      },
      "source": [
        "\r\n",
        "%tensorboard --logdir logs2  # show tensorBoard "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}